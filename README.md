# SpriteFlow: Flow-based Pixel Art Character Generation

<p float="left">
<img src="assets/unet_mid_ema/image_0.png"  alt="Example generated image"/>
<img src="assets/unet_mid_ema/image_1.png"  alt="Example generated image"/>
<img src="assets/unet_mid_ema/image_3.png"  alt="Example generated image"/>
<img src="assets/unet_mid_ema/image_10.png"  alt="Example generated image"/>
<img src="assets/unet_mid_ema/image_6.png"  alt="Example generated image"/>
<img src="assets/unet_mid_ema/image_7.png"  alt="Example generated image"/>
</p>

A PyTorch implementation of a flow-based generative model for creating 128x128 RGBA pixel 
art characters. This project uses continuous normalizing flows with a U-Net 
architecture to learn the data distribution and generate quality pixel art sprites.

## ğŸ¨ Overview
This project implements a flow-based generative model that learns to transform simple 
noise distributions (Isotropic Gaussian) into complex pixel art characters. The model uses:

- **Flow-based architecture**: Continuous normalizing flows for high-quality generation
- **U-Net backbone**: Time-conditioned U-Net for learning the vector field
- **RGBA support**: Full transparency support for pixel art sprites
- **Flexible training**: Configurable noise schedules and training parameters

## ğŸ¤– Model architecture
*TODO: Soon - Final model architecture image*

## ğŸš€ Features
- **Multiple noise schedules**: Linear and cosine scheduling options
- **Evaluation metrics**: FID (FrÃ©chet Inception Distance) for quality assessment
- **Training utilities**: Learning rate scheduling, checkpointing, and visualization
- **Flexible sampling**: Support for different generation modes and timesteps
- **Experiment tracking**: CSV logging and training visualization tools
- **Exponential Moving Average (EMA)**: Stabilizes training and improves sample quality

## ğŸ“‹ Requirements
Install the required dependencies:

```bash
pip install -r requirements.txt
```

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/                          # Your pixel art dataset (RGBA images)
â”‚   â””â”€â”€ image_only_dataset.py            # Dataset loading utilities
â”œâ”€â”€ diff_eq/
â”‚   â”œâ”€â”€ ode_sde.py                       # ODE/SDE implementations
â”‚   â””â”€â”€ simulator.py                     # Numerical integration methods
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ conditional_vector_field.py      # Conditional vector field
â”‚   â””â”€â”€ unet.py                          # U-Net architecture with time conditioning
â”œâ”€â”€ sampling/
â”‚   â”œâ”€â”€ conditional_probability_path.py  # Flow probability paths
â”‚   â”œâ”€â”€ noise_scheduling.py              # Alpha/beta scheduling functions
â”‚   â””â”€â”€ sampleable.py                    # Dataset samplers and distributions
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ ema.py                           # Exponential Moving Averag
â”‚   â”œâ”€â”€ evaluation.py                    # Evaluation metrics (FID)
â”‚   â”œâ”€â”€ lr_scheduling.py                 # Learning rate schedulers
â”‚   â”œâ”€â”€ trainer.py                       # Main training loop
â”‚   â””â”€â”€ experiments/                     # Training notebooks, outputs and checkpoints
â””â”€â”€ utils/
    â”œâ”€â”€ helpers.py                       # Utility functions
    â””â”€â”€ visualization.py                 # Training visualization tools
```


## ğŸ“Š Monitoring Training

The training process automatically logs:

- **Training loss**: Flow matching objective loss
- **Validation FID**: FrÃ©chet Inception Distance on validation set
- **Generated samples**: Saved periodically for visual inspection
- **Model checkpoints**: Best model based on validation FID

Logs are saved to `training/experiments/model_name/training_log.csv` and can be visualized using the built-in visualization tools.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
